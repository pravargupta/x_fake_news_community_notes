# x_fake_news_community_notes

I heard of the topic called as x (formerly twitter) fake news detection and was intrigued by it so I decided on reading it with little to no knowledge of ML.

As an ML beginner I had an idea which seemed fine at start but I thought that I could add community notes data given by X themselves and maybe improve and existing model.

So at first I decided to just collect such and metrics needed that could be added to a GNN model which as a beginner I found it as a pretty doable task as there was code given for it along with research

Data collection took a while but I will be trying out differnt ways to use the additional data given by X in their tsv files to first atleast make this model work.

Going to use BERT to tokenize data althought I wanted to learn how was the gossipcop and polifact data tokenized, I used a very basic BERT tokenization as there was no such research I found immediately implementable.


Implementing a very basic train and test at the moment.
